{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "\n",
    "def register(name):\n",
    "    def decorator(cls):\n",
    "        datasets[name] = cls\n",
    "        return cls\n",
    "    return decorator\n",
    "\n",
    "\n",
    "def make(dataset_spec, args=None):\n",
    "    if args is not None:\n",
    "        dataset_args = copy.deepcopy(dataset_spec['args'])\n",
    "        dataset_args.update(args)\n",
    "    else:\n",
    "        dataset_args = dataset_spec['args']\n",
    "    dataset = datasets[dataset_spec['name']](**dataset_args)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resampler(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, inp_size, interpolation_mode, resampling_factor):\n",
    "        super(Resampler, self).__init__()\n",
    "        self.inp_size = inp_size\n",
    "        self.resampling_factor = resampling_factor\n",
    "        self.interpolation_mode = InterpolationMode(interpolation_mode)\n",
    "    \n",
    "    def forward(self, img):\n",
    "        new_size = self.inp_size // self.resampling_factor\n",
    "\n",
    "        downsampler = transforms.Resize(size=(new_size,new_size), interpolation=self.interpolation_mode)\n",
    "        upsampler = transforms.Resize(size=(self.inp_size, self.inp_size), interpolation=self.interpolation_mode)\n",
    "        \n",
    "        downsampled_image = downsampler.forward(img)\n",
    "        transformed_image = upsampler.forward(downsampled_image)\n",
    "\n",
    "        return transformed_image\n",
    "\n",
    "\n",
    "@register('image-folder')\n",
    "class ImageFolder(Dataset):\n",
    "    def __init__(self, path,  split_file=None, split_key=None, first_k=None, size=None,\n",
    "                 repeat=1, cache='none', mask=False):\n",
    "        self.repeat = repeat\n",
    "        self.cache = cache\n",
    "        self.path = path\n",
    "        self.Train = False\n",
    "        self.split_key = split_key\n",
    "\n",
    "        self.size = size\n",
    "        self.mask = mask\n",
    "        if self.mask:\n",
    "            self.img_transform = transforms.Compose([\n",
    "                transforms.Resize((self.size, self.size), interpolation=Image.NEAREST),\n",
    "                transforms.ToTensor(),\n",
    "            ])\n",
    "        else:\n",
    "            self.img_transform = transforms.Compose([\n",
    "                transforms.Resize((self.size, self.size)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "\n",
    "        if split_file is None:\n",
    "            filenames = sorted(os.listdir(path))\n",
    "        else:\n",
    "            with open(split_file, 'r') as f:\n",
    "                filenames = json.load(f)[split_key]\n",
    "        if first_k is not None:\n",
    "            filenames = filenames[:first_k]\n",
    "\n",
    "        self.files = []\n",
    "\n",
    "        for filename in filenames:\n",
    "            file = os.path.join(path, filename)\n",
    "            self.append_file(file)\n",
    "\n",
    "    def append_file(self, file):\n",
    "        if self.cache == 'none':\n",
    "            self.files.append(file)\n",
    "        elif self.cache == 'in_memory':\n",
    "            self.files.append(self.img_process(file))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files) * self.repeat\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.files[idx % len(self.files)]\n",
    "\n",
    "        if self.cache == 'none':\n",
    "            return self.img_process(x)\n",
    "        elif self.cache == 'in_memory':\n",
    "            return x\n",
    "\n",
    "    def img_process(self, file):\n",
    "        if self.mask:\n",
    "            return Image.open(file).convert('L')\n",
    "        else:\n",
    "            return Image.open(file).convert('RGB')\n",
    "\n",
    "@register('paired-image-folders')\n",
    "class PairedImageFolders(Dataset):\n",
    "\n",
    "    def __init__(self, root_path_1, root_path_2, **kwargs):\n",
    "        self.dataset_1 = ImageFolder(root_path_1, **kwargs)\n",
    "        self.dataset_2 = ImageFolder(root_path_2, **kwargs, mask=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset_1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset_1[idx], self.dataset_2[idx]\n",
    "\n",
    "\n",
    "@register('train')\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, dataset, size_min=None, size_max=None, inp_size=None,\n",
    "                 augment=False, interpolation_mode=\"nearest\", resampling_factor = 1, gt_resize=None):\n",
    "        self.dataset = dataset\n",
    "        self.size_min = size_min\n",
    "        if size_max is None:\n",
    "            size_max = size_min\n",
    "        self.size_max = size_max\n",
    "        self.augment = augment\n",
    "        self.gt_resize = gt_resize\n",
    "\n",
    "        self.inp_size = inp_size\n",
    "        self.img_transform = transforms.Compose([\n",
    "                transforms.Resize((self.inp_size, self.inp_size)),\n",
    "                Resampler(inp_size = inp_size, interpolation_mode=interpolation_mode, resampling_factor=resampling_factor),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        self.inverse_transform = transforms.Compose([\n",
    "                transforms.Normalize(mean=[0., 0., 0.],\n",
    "                                     std=[1/0.229, 1/0.224, 1/0.225]),\n",
    "                transforms.Normalize(mean=[-0.485, -0.456, -0.406],\n",
    "                                     std=[1, 1, 1])\n",
    "            ])\n",
    "        self.mask_transform = transforms.Compose([\n",
    "                transforms.Resize((self.inp_size, self.inp_size)),\n",
    "                Resampler(inp_size = inp_size, interpolation_mode=interpolation_mode, resampling_factor=resampling_factor),\n",
    "                transforms.ToTensor(),\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, mask = self.dataset[idx]\n",
    "\n",
    "        # random filp\n",
    "        if random.random() < 0.5:\n",
    "            img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            mask = mask.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "        img = transforms.Resize((self.inp_size, self.inp_size))(img)\n",
    "        mask = transforms.Resize((self.inp_size, self.inp_size), interpolation=InterpolationMode.NEAREST)(mask)\n",
    "\n",
    "        return {\n",
    "            'inp': self.img_transform(img),\n",
    "            'gt': self.mask_transform(mask)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_loader(spec, tag=''):\n",
    "    if spec is None:\n",
    "        return None\n",
    "\n",
    "    dataset = make(spec['dataset'])\n",
    "    dataset = make(spec['wrapper'], args={'dataset': dataset})\n",
    "\n",
    "    loader = DataLoader(dataset, batch_size=spec['batch_size'],\n",
    "        shuffle=True, num_workers=8, pin_memory=True)\n",
    "    return loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "inp_size = 1024\n",
    "interpolation_mode = 'bicubic'\n",
    "resampling_factor = 1\n",
    "config_file = \"visualize.yaml\"\n",
    "\n",
    "# load config \n",
    "with open(config_file, 'r') as f:\n",
    "        config = yaml.load(f, Loader=yaml.FullLoader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = make_data_loader(config.get('train_dataset'), tag='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/visualize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kandelaki/miniconda3/envs/visualize/lib/python3.11/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11030). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 1024, 1024])\n"
     ]
    }
   ],
   "source": [
    "# get some random training images\n",
    "# for batch in train_loader:\n",
    "#         # for k, v in batch.items():\n",
    "#         #     batch[k] = v.to(device)\n",
    "#         inp = batch['inp']\n",
    "#         gt = batch['gt']\n",
    "batch = train_loader.__iter__().__next__()\n",
    "inp = batch['inp']\n",
    "print(inp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(inp)\n",
    "# write to tensorboard\n",
    "writer.add_image('example image', img_grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam-adapter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
